---
title: "ARIMA основи"
author: "Boyko Amarov"
date: "11/2/2021"
output: html_document
---


```{r}
library(tidyverse)
```


AR(1): auto-regressive (авто-регресионен) процес от първи ред


Дефиниция:
$$
\underbrace{y_{t}}_{\text{стойност днес}} = \delta + \alpha \underbrace{y_{t - 1}}_{\text{стойност вчера}} + \underbrace{e_{t}}_{\text{бял шум}}, \quad \delta, \alpha \in \mathbb{R}.
$$

математическо очакване 

$$
Е(y_t) = ?
$$

(Математическа) Дисперсия:


$$
Var(y_t) = E\left[\left(y_t - E(y_t)\right)^2\right]
$$
Ковариация/корелация (от първи ред)

$$
Cov(y_t, y_{t - 1}) = E\left[(y_t - E(y_t))(y_{t - 1} - E(y_t))\right]\\
Cov(y_t, y_{t - 2}) = E\left[(y_t - E(y_t))(y_{t - 2} - E(y_t))\right]\\
\vdots\\Cov(y_t, y_{t - k}) = E\left[(y_t - E(y_t))(y_{k - 2} - E(y_t))\right]\\
\rho(y_t, y_{t - 1}) = \frac{Cov(y_t, y_{t - 1})}{Var(y_t)}\\
\rho(y_t, y_{t - 2}) = \frac{Cov(y_t, y_{t - 2})}{Var(y_t)}\\
\vdots\\
\rho(y_t, y_{t - k}) = \frac{Cov(y_t, y_{t - k})}{Var(y_t)}
$$

## Напълно случаен процес

Казваме, че $e_t$  е напълно случаен процес (бял шум), ако

$$
E(e_t) = 0, t = 1,\ldots,T\\
Var(e_t) = \sigma^2, t = 1,\ldots,T\\
Cov(e_t, e_{t - k}) = 0, k \neq t
$$
$$
e_t \sim WN(\sigma^2)
$$
Симулация

```{r}
## Код за илюстрация
n <- 100

sim_data <- expand_grid(
  mu = c(0, 10),
  sigma = c(1, 3),
  t = 1:100
) %>%
  mutate(
    y = rnorm(n(), mean = mu, sd = sigma),
    sigma_lab = paste0("sigma = ", sigma),
    mu_lab = paste0("mu = ", mu)
  )

sim_data %>%
  ggplot(aes(x = t, y = y, color = mu_lab)) +
  geom_point(size = 1 / 2) +
  geom_line() +
  facet_wrap(~sigma_lab) +
  labs(
    x = "t",
    y = expression(y[t])
  )
```

```{r}
sim_data %>%
  group_by(mu_lab, sigma_lab) %>%
  summarise(
    Average = mean(y),
    StdDev = sd(y)
  )
```
Симулация

$$
y^{(1)}_{t} = e^{(1)}_t\\
y^{(2)}_{t} = 2y^{(1)}_{t} + e^{(2)}_t
$$

```{r}
n <- 100
y1 <- rnorm(n = n, mean = 0, sd = 1)
y2 <- 2 * y1 + rnorm(n = n, mean = 0, sd = 1)

tibble(y1, y2) %>%
  ggplot(aes(x = y1, y = y2)) +
    geom_point()

cov(y1, y2)
cor(y1, y2)
```

## Статистически своиства на AR(1)

$$
y_{t} = 2 + 0.5 y_{t - 1} + e_t, \quad e_t\sim WN(\sigma^2)
$$
Свойства на напълно случайния процес $e_t$:

$$
E(e_t) = 0 \text{ за всяко } t\\
Var(e_t) = \sigma^2 \text{ за всяко } t\\
Cov(e_t, e_{t - k}) = 0 \text{ за всяко } t \text{ и за всяко } k \neq 0 \\
$$
Дефиниция на дисперсия:
$$
Var(e_t) = E[(e_t - E(e_t))^2] = E[e_t^2] = \sigma^2
$$
Дефиниция на ковариация:
$$
Cov(e_t, e_{t - k}) = E[(e_t - E(e_t))(e_{t - k} - E(e_{t - k}))] = E[e_te_{t - k}] = 0, \quad k \neq 0
$$
при $k = 0$
$$
Cov(e_t, e_{t}) = E(e_te_t) = E(e_t^2) = \sigma^2
$$


Математическото очакване е линеен оператор

$$
\begin{aligned}
E(y_{t}) & = Е(2 + 0.5 y_{t - 1} + e_t)\\
         & = E(2) + E(0.5 y_{t - 1}) + \underbrace{E(e_t)}_{= 0 \text{ свойство на сл. пр.}} \text{ линейност}\\
         & = 2 + 0.5 E(y_{t - 1}) + 0\\
E(y_{t}) & = 2 + 0.5 E(y_{t - 1})
\end{aligned}
$$
Ако допуснем, че за всяко $t$ важи:

$$
E(y_t) = E(y_{t - 1}) = \mu
$$
Това допускане означава, че процесът $y_t$ е mean stationary (има стационарена средна стойност).


$$
\begin{aligned}
E(y_{t}) & = 2 + 0.5 E(y_{t - 1}) \\
        \mu & = 2 + 0.5\mu \implies \\
        (1 - 0.5)\mu & = 2\\
        \mu & =  \frac{2}{1 - 0.5} = 4
\end{aligned}
$$
$$
y_t = \delta + \alpha y_{t - 1} + e_t\quad e_t \sim WN(\sigma^2)
$$
$$
Ly_t = y_{t - 1}
$$
$$
\begin{aligned}
  y_t & = \delta + \alpha Ly_{t} + e_t\\
  y_t - \alpha Ly_{t} & = \delta + e_t\\
  (1 - \alpha L)y_t & = \delta + e_t\\
  y_{t} = \frac{\delta}{1 - \alpha L} + \frac{e_t}{1 - \alpha L}
\end{aligned}
$$
$$
\frac{1}{1 - \alpha}
$$

$$
S_n = 1 + \alpha + \alpha^2 + \alpha^3 + \alpha^4 + \alpha^5 + \ldots + \alpha^n\\
\alpha S_{n} = \alpha(1 + \alpha + \alpha^2 + \alpha^3 + \alpha^4 + \alpha^5 + \ldots + \alpha^n)\\
\alpha S_{n} = \alpha + \alpha^2 + \alpha^3 + \alpha^4 + \alpha^5 + \alpha^6 + \ldots + \alpha^n +  \alpha^{n + 1}\\
S_n - \alpha S_n = 1 - \alpha^{n + 1} \\
(1 - \alpha) S_n = 1 - \alpha^{n + 1} \\
S_n = \frac{1 - \alpha^{n + 1}}{1 - \alpha}
$$

$$
\alpha > 1, \lim_{n \to \infty} \alpha^{n + 1} = \infty\\
\alpha < -1, \lim_{n \to \infty} \alpha^{n + 1} = ???\\
-1 < \alpha < 1, \lim_{n \to \infty} \alpha^{n + 1} = 0\\
$$

$$
|\alpha| < 1 \implies \\
\lim_{n \to \infty }S_n = \lim_{n \to \infty }\frac{1 - \alpha^{n + 1}}{1 - \alpha} = \frac{1}{1 - \alpha}
$$

```{r}
## За alpha = 0.5
options(scipen=999)
(-0.5)^c(1:50)
```


```{r}
## За alpha = 0.5
options(scipen=999)
(0.5)^c(1:50)
```

```{r}
## За alpha = -2
(-2)^c(1:20)
```

$$
|\alpha| < 1\\
\frac{1}{1 - \alpha L} = (1 + \alpha L + \alpha^2 L^2 + \alpha^3L^3 + \ldots)
$$

$$
  y_{t} = \frac{\delta}{1 - \alpha L} + \frac{e_t}{1 - \alpha L}\\
  y_{t} = \delta(1 + \alpha L + \alpha^2 L^2 + \ldots) + e_t(1 + \alpha L + \alpha^2 L^2 + \ldots) \\
  y_{t} = (\delta + \alpha \delta + \alpha^2 \delta + \ldots) + e_t(1 + \alpha L + \alpha^2 L^2 + \ldots) \\
  y_{t} = \delta(1 + \alpha + \alpha^2 + \alpha^3 + \alpha^4 + \ldots) + e_t(1 + \alpha L + \alpha^2 L^2 + \ldots) \\
  y_{t} = \delta \frac{1}{1 - \alpha} + e_t(1 + \alpha L + \alpha^2 L^2 + \ldots) \\
  y_{t} = \delta \frac{1}{1 - \alpha} + (e_t + \alpha Le_t + \alpha^2 L^2e_t + \ldots)\\
  y_{t} = \delta \frac{1}{1 - \alpha} + (e_t + \alpha e_{t - 1} + \alpha^2 e_{t - 2} + \alpha^3 e_{t - 3}  + \ldots)\\
$$
$$
y_{t} = \delta \frac{1}{1 - \alpha} + (1e_t + \alpha e_{t - 1} + \alpha^2 e_{t - 2} + \alpha^3 e_{t - 3}  + \ldots)\\
  y_{t} = \frac{\delta}{1 - \alpha} + \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j}
$$
Свойства на лаг оператора
$$
Ly_{t} = y_{t - 1}\\
L^2y_{t} = L(Ly_{t}) = Ly_{t - 1} = y_{t - 2}\\
L\delta = \delta\\
L^2\delta = \delta\\
\delta_1 = 1, \delta_2 = 1,\ldots, \delta_{t - 1} = 1,  \delta_t = 1
$$


$$
\begin{aligned}
  E(y_{t}) & = \frac{\delta}{1 - \alpha}\\
  E(y_{t}) & = E\left(\frac{\delta}{1 - \alpha} + \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j}\right)\\
           & = E\left(\frac{\delta}{1 - \alpha}\right) + E\left(\sum_{j = 0}^{\infty}\alpha^{j} e_{t - j}\right) \\
           & = \frac{\delta}{1 - \alpha} + \sum_{j = 0}^{\infty}E(\alpha^{j} e_{t - j}) \\
           & = \frac{\delta}{1 - \alpha} + \sum_{j = 0}^{\infty}\alpha^{j} \underset{=0}{E( e_{t - j})} \\
  E(y_{t}) & = \frac{\delta}{1 - \alpha} \\
\end{aligned}
$$
Пример с $\alpha = 0.5, \delta = 2$:

$$
E(y_{t}) = \frac{2}{1 - 0.5} = 4
$$
$$
\begin{aligned}
  Var(y_t) & = E\left((y_t - E(y_t))^2\right)\\
  & = E\left(\left(
  \frac{\delta}{1 - \alpha} + \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j} -
  \frac{\delta}{1 - \alpha}\right)^2\right)\\
  & = E\left(\left(
  \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j}
  \right)^2\right)\\
\end{aligned}
$$

$$
\begin{aligned}
  Var(y_t) & = E\left(
  (1e_t + \alpha e_{t - 1} + \alpha^2e_{t - 2} + \ldots)(1e_t + \alpha e_{t - 1} + \alpha^2e_{t - 2} + \ldots)\right)\\
  & = E\left(
    \begin{array}{c}
    e_t^2 + \alpha e_{t}e_{t - 1} + \alpha^2e_{t}e_{t - 2} + \ldots +\\
    \alpha e_{t}e_{t - 1} + \alpha^2 e_{t - 1}^2 + \alpha^3e_{t - 1}e_{t - 2} \ldots + \\
    \alpha ^2 e_{t}e_{t - 2} + \alpha^3e_{t - 1}e_{t - 2}  + \alpha^4 e_{t - 2}^2 + \ldots +
    \end{array}
  \right)
\end{aligned}
$$

$$
\begin{aligned}
  Var(y_t) & = 
    \begin{array}{c}
    Е(e_t^2) + \alphaЕ (e_{t}e_{t - 1}) + \alpha^2Е(e_{t}e_{t - 2}) + \ldots +\\
    \alpha Е(e_{t}e_{t - 1}) + \alpha^2 Е(e_{t - 1}^2) + \alpha^3Е(e_{t - 1}e_{t - 2}) \ldots + \\
    \alpha ^2 Еe_{t}e_{t - 2} + \alpha^3Еe_{t - 1}e_{t - 2} + \alpha^4 Еe_{t - 2}^2 +  \ldots +
    \end{array}
\end{aligned}
$$
$$
\begin{aligned}
  Var(y_t) & = 
    \begin{array}{c}
    \sigma^2 + \alpha\cdot 0 + \alpha^2\cdot 0 + \ldots +\\
    \alpha \cdot 0 + \alpha^2 \sigma^2 + \alpha^3\cdot 0 \ldots + \\
    \alpha ^2\cdot 0 + \alpha^3\cdot 0 + \alpha^4 \sigma^2 +  \ldots +
    \end{array}
\end{aligned}
$$

$$
(1 + \beta + \beta^2 + \beta^3 + \beta^4 + \ldots ) = \frac{1}{1 - \beta},\quad |\beta| < 1
$$
$$
\beta = \alpha^2
$$

$$
Var(y_t) = \sigma^2 + \alpha^2 \sigma^2 + \alpha^4\sigma^2 + \ldots\\
Var(y_t) = \sigma^2(1+ \alpha^2  + \alpha^4 + \ldots)\\
Var(y_t) = \sigma^2(1+ \beta + \beta^2 + \ldots)\\
Var(y_t) = \frac{\sigma^2}{1 - \beta} = \frac{\sigma^2}{1 - \alpha^2}\\
$$

в крайна сметка получаваме, че:

$$
Var(y_t) = \frac{\sigma^2}{1 - \alpha^2}\\
$$

$$
Cov(y_{t}, y_{t - 1}) = E((y_t - E(y_t))(y_{t - 1} - E(y_{t - 1})))\\
= E
\left[
  \left(
    \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j}
  \right)
  \left(
    \sum_{j = 0}^{\infty}\alpha^{j} e_{t - j - 1}
  \right)
\right] = \\
E\left(
  \left(
    e_t + \alpha e_{t - 1} + \alpha^2 e_{t - 2} + \ldots
  \right)
  \left(
    e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots
  \right)
\right)
$$
$$
E\left(
  \left(
    e_t + \alpha e_{t - 1} + \alpha^2 e_{t - 2} + \ldots
  \right)
  \left(
    e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots
  \right)
\right) = \\
E\left[
  \left(
    e_t(e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots)
  \right)
  +\\
  (\alpha e_{t - 1} + \alpha^2 e_{t - 2} + \ldots)
  \left(
    e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots
  \right)
\right] = \\
E\left[
  (\alpha e_{t - 1} + \alpha^2 e_{t - 2} + \ldots)
  \left(
    e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots
  \right)
\right] = \\
\alpha E\left[
  ( e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} \ldots)
  \left(
    e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} + \ldots
  \right)
\right] = \\
\alpha E\left[
  ( e_{t - 1} + \alpha e_{t - 2} + \alpha^2 e_{t - 3} \ldots)^2
\right] = \\

\alpha Var(y_{t  -1}) = \\
Cov(y_{t}, y_{t - 1}) = \alpha \frac{\sigma^2}{1 - \alpha^2}

$$
$$
\rho(y_{t}, y_{t - 1}) = \frac{Cov(y_t, y_{t - 1})}{Var(y_t)}
$$

$$
\rho = \frac{\alpha\frac{\sigma^2}{1 - \alpha^2}}{\frac{\sigma^2}{1 - \alpha^2}} = \alpha
$$
За домашно покажете, че

$$
Cov(y_{t}, y_{t - 2}) = \alpha^2\frac{\sigma^2}{1 - \alpha^2}\\
\rho(y_t, y_{t - 2}) = \alpha^2
$$

$$
k \neq 0\\
Cov(y_{t}, y_{t - k}) = \alpha^k\frac{\sigma^2}{1 - \alpha^2}\\
\rho(y_t, y_{t - k}) = \alpha^k
$$
## Задача от лекциите

AR(1)

Без ограничение на общовалидността $\delta = 0$.

$$
y_t = \phi_{1}y_{t - 1} + e_t,  \quad e_t\sim WN(\sigma^2)
$$

$$
(1 - \phi_1 B)y_{t} = e_{t}
$$
$$
1 - \phi_1 B = 0\\
\phi_1 B = 1\\
B = \frac{1}{\phi_1}
$$

$$
1B^{0} - \phi_1 B^1
$$

Характеристично уравнение
$$
\lambda^{1 - 0} - \phi_1 \lambda^{1 - 1} = 0\\
\lambda - \phi_1 = 0
$$

$$
\lambda^* = \phi_1
$$

$$
\phi_1 = 1
$$

Random walk (случайно лутане)
$$
y_{t} = y_{t - 1} + e_t\\
$$
$$
y_t = y_{t - 4} + e_{t - 3} + e_{t - 2} + e_{t- 1} + e_t\\
$$
$$
y_{t} = \sum_{k = 1}^{t}e_{k}
$$

Тъй като $Cov(e_t, e_{t - k}) = 0$

$$
Cov(e_t, e_{t - k}) = 0, k\neq 0\\
Var(y_{t}) = Var\left(\sum_{k = 0}^{t}e_{k}\right) = \sum_{k = 0}^{t}Var(e_{k})\\
Var(y_{t}) = \sum_{k = 1}^{t}\sigma^2 = (\sigma^2 + \sigma^2 + \ldots + \sigma^2)\\
Var(y_{t}) = t\sigma^2
$$
AR(1)

$$
y_{t} = \phi_1 y_{t - 1} + e_t, |\phi_1| < 1\\
Var(y_{t}) = \frac{\sigma^2}{1 - \phi_1^2}
$$

```{r}
ar1_stationary <- arima.sim(n = 100, model = list(ar = c(0.5)))
plot(ar1_stationary)
```

```{r}
e <- rnorm(n = 100)
rw <- cumsum(e)
plot(rw, type = "n")
lines(1:100, rw)
```
AR(2)

$$
y_{t} = \phi_1y_{t - 1} + \phi_2 y_{t - 2} + e_t\\
y_{t}(B^{0} - \phi_1 B^{1} - \phi_2 B^2 ) = e_{t}
$$
Характеристично уравнение


$$
\lambda^{2 - 0} - \phi_1 \lambda^{2 - 1} - \phi_2 \lambda^{2 - 2} = 0\\
\lambda^{2} - \phi_1 \lambda - \phi_2 = 0
$$
Пример
$$
y_{t} = 0.5y_{t - 1} + 0.2y_{t- 1} + e_t
$$

$$
\lambda^{2} - 0.5 \lambda - 0.2 = 0
$$
```{r}
roots <- polyroot(c(-0.2, -0.5, 1))
roots
```

```{r}
abs(roots)
```


Решенията на уравнението са:
$$
\lambda_1^* = -0.26\\
\lambda_2^* = 0.76\\
$$
$$
(\lambda - \lambda_1^*)(\lambda - \lambda_2^*) = 0
$$
Ако са ни дадени корените на характеристичното уравнение можем
да стигнем до коефициентите на процеса $ph_1, phi_2$.

$$
(\lambda + 0.26)(\lambda - 0.76) = \\
\lambda^2 - 0.76\lambda + 0.26\lambda - 0.1976 = \\
\lambda^2 - 0.5\lambda - 0.1976 \\
\lambda^{2} - \phi_1 \lambda - \phi_2 = 0
$$

$$
\phi_1 = 0.5 \\
\phi_2 = 0.1976
$$

$$
\rho_1 = ???
$$

Yule-Walker за AR(2) процес.

$$
\rho_1 = \phi_1 \rho_0 + \phi_2 \rho_1\implies\\
(1 - \phi_2)\rho_1 = \phi_1\rho_0 =\\
\rho_1 = \frac{\phi_1}{1 - \phi_2}
$$


В примера с:

$$
\phi_1 = 0.5\\
\phi_2 = 0.2\\
\rho_1 = \frac{0.5}{1 - 0.2} = ???
$$

$$
\rho_0 = Cor(y_{t}, y_{t}) = 1
$$
$$
\rho_2 = ?
$$
$$
\rho_1 = \phi_1 \rho_0 + \phi_2 \rho_1
$$
$$
\rho_2 = \phi_1 \rho_{1} + \phi_2\rho_{0}
$$

$$
\rho_2 = \phi_1 \rho_{1} + \phi_2\\
\rho_2 = \phi_1 \frac{\phi_1}{1 - \phi_2} + \phi_2\\
\rho_2 = 0.5 \frac{0.5}{1 - 0.2} + 0.2 = ???\\
$$
$$
y_t = \phi_{1}y_{t - 1} + \phi_2y_{t - 2} + \underbrace{\phi_3}_{ = 0}y_{t- 3} + e_t,  \quad e_t\sim WN(\sigma^2)
$$
## Moving average: MA(q)


$$
e_{t} \sim WN(\sigma^2)\\
y_{t} = e_{t} + \theta_1 e_{t - 1} \text{ MA(1)}\\
y_{t} = e_{t} + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} \text{ MA(2)}\\
y_{t} = e_{t} + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} + \ldots +\theta_q e_{t - q} \text{ MA(q)}\\
$$


$$
\text{за всяко } t\\
E(e_t) = 0\\
Var(e_t) = E(e_t^2) = \sigma^2\\
Var(e_{t - 1}) = E(e_{t - 1}^2) = \sigma^2\\
Cov(e_t, e_{t - k}) = E(e_t e_{t - k}) = 0, k \neq 0
$$


Пример МА(1)
$$
y_{t} = e_t + 0.5e_{t - 1}
$$

$$
E(y_t)= E(e_t) + 0.5E(e_{t - 1}) = 0 + 0.5\cdot 0 = 0\\
$$
$$
Var(y_t) = E[(y_t - E(y_t))^2] = E[(e_t + 0.5e_{t - 1})^2]\\
Var(y_t) = E[e_t^2 + 2\cdot 0.5 e_t e_{t - 1} + 0.5^2e_{t - 1}^2] = \\
= E[e_t^2] + E[2\cdot 0.5 e_t e_{t - 1}]+ E[0.5^2e_{t - 1}^2] = \\
= \sigma^2 + 0+ 0.5^2\sigma^2 = \\
= \sigma^2 + 0.5^2\sigma^2 = \\
= \sigma^2(1  + 0.5^2)
$$

$$
Var(y_{t}) = \sigma^2(1  + \theta_1^2)
$$

$$
Cov(y_{t}, y_{t - 1}) = E[(y_{t} - E(y_{t}))(y_{t - 1} - E(y_{t - 1}))]\\
Cov(y_{t}, y_{t - 1}) = E[y_{t}y_{t - 1}]\\
= E[(e_t + 0.5e_{t - 1})(e_{t - 1} + 0.5e_{t - 2})] = \\
= E[e_te_{t-1} + 0.5e_{t}e_{t - 2} + 0.5 e_{t - 1}^2 + 0.5^2e_{t- 1}e_{t - 2}]\\
= E[e_te_{t-1}] + 0.5E[e_{t}e_{t - 2}] + 0.5E[e_{t - 1}^2] + 0.5^2E[e_{t- 1}e_{t - 2}] = \\
= 0 + 0.5\cdot 0 + 0.5\sigma^2 + 0.5^2 \cdot 0 = \\
= 0.5\sigma^2 \\
$$

$$
Cov(y_{t}, y_{t - 1}) = \theta_1 \sigma^2
$$

$$
\rho(y_{t}, y_{t - 1}) = \frac{Cov(y_{t}, y_{t - 1})}{Var(y)} = \frac{\theta_1 \sigma^2}{\sigma^2(1  + \theta_1^2)} = \frac{\theta_1}{1 + \theta_1^2}
$$


$$
y_{t} = e_t + \theta_1 e_{t - 1} = e_t + \theta_1 L e_{t} = \\
y_{t} = e_{t}(1 + \theta_1 L)\\
\frac{y_{t}}{1 + \theta_1 L} = e_{t}\\
\sum_{k = 1}^{\infty} \theta_1^{k} y_{t - k} = e_t
$$

$$
y_{t} = \phi_1 y_{t - 1} + e_t\\
y_{t} = \frac{e_{t}}{1 - \phi_1 L} = \sum_{k = 1}^{\infty}\phi_1^{k} e_{t - k}
$$

MA(3)
$$
y_{t} = e_t + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} + \theta_3 e_{t - 3}\\
E(y_{t}) = 0\\
Var(y_{t}) = Var(e_t) + \theta_1^2 Var(e_{t - 1}) + \theta_2^2 Var(e_{t - 2}) + \theta_3^2Var(e_{t - 3}) = \\
Var(y_{t}) = \sigma^2 + \theta_1^2 \sigma^2 + \theta_2^2\sigma^2 + \theta_3^2 \sigma^2 = \\
Var(y_{t}) = \sigma^2(1 + \theta_1^2 + \theta_2^2 + \theta_3^2)
$$
$$
Cov(y_{t}, y_{t - 1}) = E(y_{t}y_{t - 1}) = \\
E[(e_t + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} + \theta_3 e_{t - 3})(e_{t - 1} + \theta_1 e_{t - 2} + \theta_2 e_{t - 3} + \theta_3 e_{t - 4})] = \\
E[\theta_1e_{t - 1}^2 + \theta_2\theta_1e_{t - 2}^2 \theta_3\theta_2e_{t - 3}^2]= \\
\theta_1\sigma^2 + \theta_2\theta_1 \sigma^2 + \theta_3\theta_2\sigma^2 = 
\sigma^2 (\theta_1 + \theta_2\theta_1 + \theta_3\theta_2) = 
$$

$$
Cov(y_{t}, y_{t - 2}) = E(y_{t}y_{t - 2}) = \\
E[(e_t + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} + \theta_3 e_{t - 3})(e_{t - 2} + \theta_1 e_{t - 3} + \theta_2 e_{t - 4} + \theta_3 e_{t - 5})] =\\
E[\theta_2 e_{t - 2}^2 + \theta_3 \theta_1 e_{t - 3}^2] = 
\sigma^2(\theta_2 + \theta_3\theta_1)
$$
$$
Cov(y_{t}, y_{t - 4}) = E(y_{t}y_{t - 4}) = \\
E[(e_t + \theta_1 e_{t - 1} + \theta_2 e_{t - 2} + \theta_3 e_{t - 3})(e_{t - 4} + \theta_1 e_{t - 5} + \theta_2 e_{t - 6} + \theta_3 e_{t - 7})] = 0
$$

```{r}
x_ma_3 <- arima.sim(n = 100, model = list(ma = c(0.5, 0.2, 0.2)))
```



```{r}
plot(x_ma_3)
```

```{r}
acf(x_ma_3)
```

```{r}
x_ar_1 <- arima.sim(n = 100, model = list(ar = c(0.7)))
plot(x_ar_1)
```
```{r}
acf(x_ar_1)
```

